{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3d57e3-fca4-4367-ac34-c1d1ebaf3ef0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Audio estéreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d78c55c-fb62-4c82-831f-4d384c2b4eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importacion.\n",
    "from scipy.io import wavfile\n",
    "import IPython\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directorios que usaremos.\n",
    "cwd = os.getcwd()\n",
    "audio_input_path = os.path.join(cwd, os.path.join('audio', '_input'))  # audio_examples\n",
    "audio_output_path = os.path.join(cwd, os.path.join('audio', '_output'))\n",
    "print(f'Path to input audio: {audio_input_path}')\n",
    "print(f'Path to output audio: {audio_output_path}\\n')\n",
    "\n",
    "\n",
    "# Cargamos el archivo de audio.\n",
    "filename = os.path.join(audio_input_path, 'breaking_bad.wav')\n",
    "sample_rate, audio_data = wavfile.read(filename)\n",
    "print(f'Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz')\n",
    "\n",
    "\n",
    "\n",
    "# Mostrar informacion (sonido estéreo).\n",
    "print('Datos de audio (estereo):')\n",
    "print(f'- Tamaño:     {audio_data.shape}')\n",
    "print(f'- 1º canal:   {audio_data[:5, 0]}...')\n",
    "print(f'- 2º canal:   {audio_data[:5, 1]}...')\n",
    "print(f'- Resolucion: {type(audio_data[0,0])}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805160a3-47d0-43ac-a6e7-334fa9fc8c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_data.T, rate=sample_rate) # .T se pasa únicamente si es audio estéreo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed02da9-647c-4279-8937-8d3129702988",
   "metadata": {},
   "source": [
    "# Audio mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668bba2-b4e8-4f57-b774-3680b7a56c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertimos a mono mediante la media por canal (simplificacion).\n",
    "new_data_mono = audio_data.mean(axis=1)  # Column-wise.\n",
    "print('Nuevos datos de audio (mono):')\n",
    "print(f'- Nuevo tamaño: {new_data_mono.shape}')\n",
    "print(f'- Canal unico:  {new_data_mono[:5]}...')\n",
    "\n",
    "# Mantenemos la misma resolucion que antes.\n",
    "new_data_mono = new_data_mono.astype(np.int16)\n",
    "print(f'- Resolucion:   {type(new_data_mono[0])}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac630571-9a8b-4f9c-a800-bec5eac6dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el archivo mono a un fichero de tipo wav.\n",
    "wavfile.write(\n",
    "    filename=os.path.join(audio_output_path, 'sample1_mono.wav'),\n",
    "    rate=sample_rate,\n",
    "    data=new_data_mono\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7cf07f-cdfd-4627-aaab-0e567227e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_data_mono, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1befd0-ed96-44cc-b708-0251a7c6752d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2101da-ee4d-4698-bca6-f6a8a7253939",
   "metadata": {},
   "source": [
    "## Comparación del tipo de audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd3d8cb-a381-4ae8-9eb8-221cdac920ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -sh audio/_input/breaking_brad.wav\n",
    "!ls -sh audio/_output/sample1_mono.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9771d5-17b7-4687-83e5-b2b8ba31559c",
   "metadata": {},
   "source": [
    "# Gráfica del dominio del tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008a011-cfeb-402a-b46e-314a67dc8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ampl_values_estereo = len(audio_data)\n",
    "ampl_values_mono = len(new_data_mono)\n",
    "print(f'Número de muestras del audio (valores de amplitud): {ampl_values_estereo}')\n",
    "print(f'Número de muestras del audio (valores de amplitud): {ampl_values_mono}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e94cf8-91f8-4199-a7fa-6d01f54b6f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el array para el eje x que representa el tiempo de la grabación.\n",
    "# Tiene la forma: np.arange(Vi, Vf, P). Explicado a continuación.\n",
    "t1 = np.arange(0, ampl_values_estereo/sample_rate, 1/sample_rate)\n",
    "t2 = np.arange(0, ampl_values_mono/sample_rate, 1/sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edebf078-aeb4-4816-a1e0-3066652b8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae8d51-279e-4d8f-a254-3546b7452ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creamos la figura.\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# Solo mostramos las primeras 50 muestras de amplitud (por claridad).\n",
    "begin = 7500\n",
    "end = 10000\n",
    "\n",
    "# Señal a 48 kHz.\n",
    "ax[0].plot(t1[begin:end], audio_data[begin:end], marker='X')\n",
    "ax[0].set_title(f'Audio en el dominio del tiempo muestreado del audio estéreo')\n",
    "ax[0].set_ylabel('Amplitud')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(t2[begin:end], new_data_mono[begin:end], c='tab:red', marker='X')\n",
    "ax[1].set_title(f'Audio en el dominio del tiempo muestreado del audio mono')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Amplitud')\n",
    "ax[1].grid(True)\n",
    "\n",
    "# Mostramos la figura.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b574127-c71f-489f-b70f-dbdd7c38a67b",
   "metadata": {},
   "source": [
    "Se ha añadido al inicio del código \"begin = 7500\" debido a que el audio de breaking_bad tarda en empezar y así se puede observar perfectamente la gráfica del dominio del tiempo de los audios estéreo y mono.\n",
    "Se ha quitado la variable ratio, ya que se utilizaba en el notebook proporcionado por el profesor porque los audios eran de diferente frecuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba803c-de06-4d6e-8e8a-505d94ba643c",
   "metadata": {},
   "source": [
    "## Audio estéreo y mono\n",
    "En el audio mono se escucha el mismo sonido por el auricular derecho que por el auricular izquierdo, mientras que en el estéreo se escuchan sonidos diferentes aunque en su combinación reproduzcan el mismo sonido.\n",
    "## ¿Qué es la frecuencia de muestreo?\n",
    "Es el número de muestras por segundo que tomamos del audio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda2a1bd-ef4d-4da3-865d-bcaf28af8f17",
   "metadata": {},
   "source": [
    "## ¿Qué es el aliasing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1a4f8-f917-4082-b852-3b59bdc80763",
   "metadata": {},
   "source": [
    "Es un efecto que provoca que señales continuas las cuales sean diferentes, se muestren iguales, debido a una frecuencia de muestreo demasiado baja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb126f-114a-4072-8b16-ffc992dd18d5",
   "metadata": {},
   "source": [
    "## ¿Qué es la profundidad de bits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde38f77-8fda-4c91-9744-984501890041",
   "metadata": {},
   "source": [
    "Indica cuantos bits hay disponibles para medir la onda sonora, además para que se almacenen nuestras muestras en bytes digitales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caf51fe-fab5-4ebf-97d0-36b08db21a6b",
   "metadata": {},
   "source": [
    "## ¿Qué es la tasa de bits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd9c4ff-81ca-4f0b-807a-4d57d9a5d7db",
   "metadata": {},
   "source": [
    "Indica el tamaño del archivo de audio digital"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236418ce-0414-458b-b0c4-d895f9af9e50",
   "metadata": {},
   "source": [
    "# Transformada de Fourirer (FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9170b-dfc7-444a-ba4f-e77cb666311e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# La longitud del array de datos y el\n",
    "# sample rate (frecuencia de muestreo).\n",
    "n = len(new_data_mono)\n",
    "Fs = sample_rate\n",
    "\n",
    "# Working with stereo audio, there are two channels in the audio data.\n",
    "# Let's retrieve each channel seperately:\n",
    "# ch1 = np.array([data[i][0] for i in range(n)]) #channel 1\n",
    "# ch2 = np.array([data[i][1] for i in range(n)]) #channel 2\n",
    "# We can then perform a Fourier analysis on the first\n",
    "# channel to see what the spectrum looks like.\n",
    "\n",
    "# Calculando la Transformada Rapida de Fourier (FFT) en audio mono.\n",
    "ch_Fourier = np.fft.fft(new_data_mono)  # ch1\n",
    "\n",
    "# Solo miramos frecuencia por debajo de Fs/2\n",
    "# (Nyquist-Shannon) --> Spectrum.\n",
    "abs_ch_Fourier = np.absolute(ch_Fourier[:n//2])\n",
    "\n",
    "# Graficamos.\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud', labelpad=10)\n",
    "plt.xlabel('$f$ (Hz)', labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ad5a9-e56e-4f0e-8c77-3bc6fccdb2c0",
   "metadata": {},
   "source": [
    "Se realiza con el audio mono y se puede observar que hay solo un canal, se carga el audio mono utilizando \"new_data_mono\" la variable sample_rate es igual tanto en estéreo como en mono."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32055ba-baa0-4753-b15d-5bfa87191c95",
   "metadata": {},
   "source": [
    "## ¿Por qué se realiza la Transformada de Fourier?\n",
    "Se utiliza para descomponer la señal del audio en sus componentes espectrales individuales, aportando información de su composición."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7338a09-d697-48d9-af1a-def3b681acbf",
   "metadata": {},
   "source": [
    "# Energía del espectograma y frecuencia de corte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb96a2f-ba1e-40cd-94bd-d7028b5a49bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definimos epsilon: la parte de la energia\n",
    "# del espectro que no conservamos.\n",
    "eps = [1e-5, .02, .041, .063, .086, .101, .123]\n",
    "\n",
    "# Jugamos con los valores de epsilon (CAMBIAD ESTO).\n",
    "eps = eps[6]\n",
    "print(f'Epsilon: {eps}')\n",
    "\n",
    "# Calculamos el valor de corte para esta energia.\n",
    "thr_spec_energy = (1 - eps) * np.sum(abs_ch_Fourier)\n",
    "print(f'Valor de corte para la energia del espectro: {thr_spec_energy}')\n",
    "\n",
    "# Integral de la frecuencia --> energia del espectro.\n",
    "spec_energy = np.cumsum(abs_ch_Fourier)\n",
    "\n",
    "# Mascara (array booleano) que compara el valor\n",
    "# de corte con la energia del espectro.\n",
    "frequencies_to_remove = thr_spec_energy < spec_energy  \n",
    "print(f'Mascara: {frequencies_to_remove}')\n",
    "\n",
    "# La frecuencia f0 por la que cortamos el espectro.\n",
    "f0 = (len(frequencies_to_remove) - np.sum(frequencies_to_remove)) * (Fs/2) / (n//2)\n",
    "print(f'Frecuencia de corte f0 (Hz): {int(f0)}')\n",
    "\n",
    "# Graficamos.\n",
    "plt.axvline(f0, color='r')\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud')\n",
    "plt.xlabel('$f$ (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed7d56-d017-4ca6-a962-bb20bb10a2b6",
   "metadata": {},
   "source": [
    "# Compresión de la onda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ef84e-cf25-4db1-874f-775ab3346d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definimos los nombres de los audios comprimidos.\n",
    "wav_compressed_file = \"sample_48kHz_compressed.wav\"\n",
    "\n",
    "# Calculamos el factor D de downsampling.\n",
    "D = int(Fs / f0)\n",
    "print(f'Factor de downsampling: {D}')\n",
    "\n",
    "# Obtenemos los nuevos datos (slicing with stride).\n",
    "new_data = new_data_mono[::D]\n",
    "\n",
    "# Escribimos los datos a un archivo de tipo wav.\n",
    "wavfile.write(\n",
    "    filename=os.path.join(audio_output_path, wav_compressed_file),\n",
    "    rate=int(Fs/D),\n",
    "    data=new_data\n",
    ")\n",
    "\n",
    "# Cargamos el nuevo archivo.\n",
    "new_sample_rate, new_audio_data = wavfile.read(filename=os.path.join(audio_output_path, wav_compressed_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add67c87-57a3-4a11-95c0-c6d6dfb609ea",
   "metadata": {},
   "source": [
    "En el código de este apartado y el anterior, contamos con un vector con 7 valores distintos para epsilon, cuanto mayor sea el valor de epsilon, mayor energía va a descartar en la pista del audio, entonces se escuchará una versión empeorada del audio mono, si la constante epsilon es muy pequeña la energía que se descarta es mínima por lo cual se esuchará el audio apenas sin diferencias con el audio mono original.\n",
    "También se puede observar el valor de corte para la energía, que es el valor de la energía en el momento del corte.\n",
    "La máscara indica true si epsilon tiene un valor que pertenece a un fragmento eliminado o false si epsilon contiene un valor que no se debe eliminar.\n",
    "La frecuencia de corte que es cuando a partir de esa frecuencia se descarta la energía.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169a23f-092e-4a94-8041-2c45aa8dc8a3",
   "metadata": {},
   "source": [
    "# Mostrar el espectograma de ambas ondas: original y comprimida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392055a8-2c6b-436d-892d-1f62b549c002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[0].specgram(new_data_mono, NFFT=1024, Fs=sample_rate, noverlap=512)\n",
    "ax[0].set_title('Espectograma del audio original')\n",
    "ax[0].set_ylabel('Frecuencia (Hz)')\n",
    "ax[0].grid(True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[1].specgram(new_audio_data, NFFT=1024, Fs=new_sample_rate, noverlap=512)\n",
    "ax[1].set_title('Espectrograma del audio reducido/comprimido')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Frecuencia (Hz)')\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e560f8-d319-4d0a-bd12-e3e9ba4581d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -sh audio/_output/sample_48kHz_compressed.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2809c6-5019-4616-ac96-4a21b7f748a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -sh audio/_output/sample1_mono.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fd738f-ed2c-46da-9ff6-3314e3c3de1d",
   "metadata": {},
   "source": [
    "Se puede observar como el audio comprimido ocupa mucho menos espacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3843b81-7dd7-4e09-abb2-99ed3c173431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_audio_data, rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705cc2fa-cf88-4fa6-8ed8-6e4935bb6dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_data_mono, rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno_conda1",
   "language": "python",
   "name": "entorno_conda1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
